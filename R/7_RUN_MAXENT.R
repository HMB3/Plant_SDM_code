#########################################################################################################################
#############################################  FIT MAXENT TO GBIF DATA ################################################## 
#########################################################################################################################


#########################################################################################################################
## This code takes a table of all species occurrences (rows) and environmental values (columns), and runs SDMs for a list
## of taxa. First, targetted background selection is used. Then, backwards selection is used on the occurrence and 
## background points generated by the targetted selection.


## Print the species run to the screen
message('Running maxent models for ', length(GBIF.spp), ' species in the set ', "'", save_run, "'")


##########################################################################################################################
## Load SDM table.
if(read_data == "TRUE") {
  
  ## This table will be all the records for all HIA species (~3.8k). These data will be re-processed, 1000 species at
  SDM.SPAT.OCC.BG = readRDS(paste0(DATA_path, 'SDM_SPAT_OCC_BG_ALL_EVERGREEN_SPP.rds'))
  
} else {
  
  message(' skip file reading, not many species analysed')   ##
  
}



#########################################################################################################################
## 1). RUN SDMs USING ALL A-PRIORI VARIABLES FOR ALL SPECIES
#########################################################################################################################


#########################################################################################################################
## Run Maxent using a targetted selection of background points. 
## within 200km of existing points
## Within the same Koppen zone as the existing points
## Try to sample bg points from the three sources (ALA/GBIF/INV in the same proportions as the occurrece data).
dim(SDM.SPAT.OCC.BG)
length(intersect(unique(SDM.SPAT.OCC.BG$searchTaxon), GBIF.spp))  ## Should be same length as GBIF.spp
projection(template.raster.1km);projection(SDM.SPAT.OCC.BG);projection(Koppen_1975_1km)


## Can error messages be saved inside the text file......................................................................
## Check why the BG sampling is not messaging.


# #########################################################################################################################
# ## Loop over all the species = GBIF.spp[1]
lapply(GBIF.spp, function(species){ 
   
   ## Skip the species if the directory already exists, before the loop
   outdir <- maxent_dir
   
   dir_name = file.path(maxent_path, gsub(' ', '_', species))
   if(dir.exists(dir_name)) {
     message('Skipping ', species, ' - already run.')
     invisible(return(NULL))
     
   }
   
   ## Create the directory for the species in progress, 
   ## so other parallel runs don't run the same species
   dir.create(dir_name)
   file.create(file.path(dir_name, "in_progress.txt"))
   #write.csv(data.frame(), file.path(dir_name, "in_progress.txt"))
   
   ## Print the taxa being processed to screen
   if(species %in% SDM.SPAT.OCC.BG$searchTaxon) {
     message('Doing ', species) 
     
     ## Subset the records to only the taxa being processed
     ## Also subset to the source : ALA+ GBIF, or ALA + GBIF + INV
     ## This is what is causing the proportional sampling to skip.........................................
     occurrence <- subset(SDM.SPAT.OCC.BG, searchTaxon == species)
     occurrence <- occurrence[grep(paste(OCC_SOURCE, collapse = '|'), occurrence$SOURCE, ignore.case = TRUE),]
     message('Using occ records from ', unique(occurrence$SOURCE))
 
     ## Now get the background points. These can come from any species, other than the modelled species.
     ## However, they should be limited to the same SOURCE as the occ data
     background <- subset(SDM.SPAT.OCC.BG, searchTaxon != species)
     background <- background[grep(paste(unique(occurrence$SOURCE), collapse = '|'), background$SOURCE, ignore.case = TRUE),]
     message('Using bg records from ', unique(background$SOURCE))
 
     
     ## Finally fit the models using FIT_MAXENT_TARG_BG. Also use tryCatch to skip any exceptions
     tryCatch(
       fit_maxent_targ_bg_back_sel(occ                     = occurrence,    ## name from the .rmd CV doc 
                                   bg                      = background,    ## name from the .rmd CV doc  
                                   sdm.predictors          = bs.predictors, 
                                   name                    = species, 
                                   outdir                  = maxent_dir,
                                   bsdir                   = bs_dir,
                                   backwards_sel           = "TRUE",
                                   cor_thr                 = 0.8,      ## The maximum allowable pairwise correlation between predictor variables
                                   pct_thr                 = 5,        ## The minimum allowable percent variable contribution
                                   k_thr                   = 4,        ## The minimum number of variables to be kept in the model.
                                   
                                   template.raster         = template.raster.1km,
                                   min_n                   = 20,            ## This should be higher...
                                   max_bg_size             = 70000,         ## could be 50k or lower, it just depends on the biogeography
                                   Koppen                  = Koppen_1975_1km,
                                   background_buffer_width = 200000,
                                   shapefiles              = TRUE,
                                   features                = 'lpq',
                                   replicates              = 5,
                                   responsecurves          = TRUE,
                                   shp_path                = "./data/base/CONTEXTUAL/", 
                                   aus_shp                 = "aus_states.rds"),
       
       ## If the species fails, write a fail message to file. Can this be the fail message itself?
       error = function(cond) {
         
         ## How to put the message into the file?
         file.create(file.path(dir_name, "sdm_failed.txt"))
         message(species, ' failed') 
         cat(cond$message, file=file.path(dir_name, "sdm_failed.txt"))
         warning(species, ': ', cond$message)
       })
     
   } else {
     
     message(species, ' skipped - no data.')         ## This condition ignores species which have no data...
     file.create(file.path(dir_name, "completed.txt"))
     
   }  
   
   ## now add a file to the dir to denote that it has completed
   file.create(file.path(dir_name, "completed.txt"))
   
 })





#########################################################################################################################
## 2). TABULATE MAXENT STATISTICS - ADD NICHE DATA LATER
#########################################################################################################################


## The code that adds niche info is now in './R/COLLATE_MAXENT_RESULTS.R' 
## The code below is just for running on Katana
## Print the species run to the screen
message('Creating summary stats for ', length(GBIF.spp), ' species in the set ', "'", save_run, "'")


#########################################################################################################################
## First, make a list of all the species with models, then restrict them to just the models on the GBIF.spp list 
map_spp_list  = gsub(" ", "_", GBIF.spp)
map_spp_patt  = paste0(map_spp_list, collapse = "|")
message ("map_spp_list head:")
message (paste (head(map_spp_list), collapse=","))


#########################################################################################################################
## Now stop R from creating listing all the maxent files that have completed - this takes a long time
#message ("DEBUGDEBUG - remember to disable next line")
#map_spp_list = head (map_spp_list)
message(results_dir)
maxent.tables = lapply (map_spp_list, FUN = function (x) {paste(results_dir , x, "full/maxent_fitted.rds", sep="/")})


## How many species have been modelled?
message(paste("maxent.tables has this many entries:", length(maxent.tables)))
message(paste(head (maxent.tables), collapse=","))
sdm.exists = lapply(maxent.tables, FUN = function (x) {file.exists (x)})
sdm.exists = unlist(sdm.exists)


## Only list the intersection between the modelled species and 
message(paste(head(sdm.exists), collapse=","))
maxent.tables = maxent.tables[sdm.exists]


message (paste ("maxent.tables has this many entries:", length(maxent.tables)))
maxent.tables = stringr::str_subset(maxent.tables, map_spp_patt)
message (paste ("maxent.tables has this many entries:", length(maxent.tables)))
message (paste (head(maxent.tables), collapse=","))


#########################################################################################################################
## Now create a table of the results 
## x = maxent.tables[1]
MAXENT.RESULTS <- maxent.tables %>%         
  
  ## Pipe the list into lapply
  lapply(function(x) {
    
    ## We don't need to skip species that haven't been modelled
    x = gsub(paste0(results_dir, "/"), "", x) 
    message (x)
    
    #############################################################
    ## load the backwards selected model
    if (grepl("BS", results_dir)) {
      m = readRDS(paste0(results_dir, '/',  x))
      
    } else {
      ## Get the background records from any source
      m = readRDS(paste0(results_dir, '/',  x))$me_full
      
    }
    
    ## Get the number of Variables
    number.var  = length(m@lambdas) - 4   ## (the last 4 slots of the lambdas file are not variables)
    mxt.records = nrow(m@presence)
    
    ## Get variable importance
    m.vars    = ENMeval::var.importance(m)
    var.pcont = m.vars[rev(order(m.vars[["percent.contribution"]])),][["variable"]][1]
    pcont     = m.vars[rev(order(m.vars[["percent.contribution"]])),][["percent.contribution"]][1]
    
    var.pimp  = m.vars[rev(order(m.vars[["permutation.importance"]])),][["variable"]][1]
    pimp      = m.vars[rev(order(m.vars[["permutation.importance"]])),][["permutation.importance"]][1]
    
    ## Get maxent results columns to be used for model checking
    ## Including the omission rate here
    Training_AUC             = m@results["Training.AUC",]
    Number_background_points = m@results["X.Background.points",]
    Logistic_threshold       = m@results["X10.percentile.training.presence.Logistic.threshold",]
    Omission_rate            = m@results["X10.percentile.training.presence.training.omission",]
    
    ## Now rename the maxent columns that we will use in the results table
    d = data.frame(searchTaxon              = x, 
                   Maxent_records           = mxt.records,
                   Number_var               = number.var, 
                   Var_pcont                = var.pcont,
                   Per_cont                 = pcont,
                   Var_pimp                 = var.pimp,
                   Perm_imp                 = pimp,
                   Training_AUC,
                   Number_background_points,  
                   Logistic_threshold,
                   Omission_rate)
    
    ## Remove path gunk, and species
    d$Species     = NULL
    d$searchTaxon = gsub("/full/maxent_fitted.rds", "", d$searchTaxon)
    return(d)
    
  }) %>%
  
  ## Finally, bind all the rows together
  bind_rows


#########################################################################################################################
## Now create a list of the '10th percentile training presence Logistic threshold'. This is used in step 8 to threshold
## the maps to just areas above the threshold.
message ("MAXENT.RESULTS columns") 
message (paste (colnames (MAXENT.RESULTS)))
message (paste (nrow (MAXENT.RESULTS)))
summary(MAXENT.RESULTS["Logistic_threshold"])   
percent.10.log = as.list(MAXENT.RESULTS["Logistic_threshold"])  
percent.10.log = percent.10.log$Logistic_threshold


#########################################################################################################################
## Create a list of the omission files - again, don't do this for all the files, just the intersection
omission.tables = lapply (map_spp_list, FUN = function (x) {paste(results_dir , x, "full/species_omission.csv", sep="/")})
message (head (omission.tables))


## Only process the existing files 
om.exists = lapply (omission.tables, FUN = function (x) {file.exists (x)})
om.exists = unlist(om.exists)


omission.tables = omission.tables[om.exists]
message(head(omission.tables))


## Get the maxium TSS value using the omission data : use _training_ ommission data only
Max_tss <- sapply(omission.tables, function(file) {
  
  ## For eachg species, read in the training data
  d <- read.csv(file)
  i <- which.min(d$Training.omission + d$Fractional.area)
  
  c(Max_tss = 1 - min(d$Training.omission + d$Fractional.area),
    thr     = d$Corresponding.logistic.value[i])
  
})



#########################################################################################################################
## Add a species variable to the TSS results, so we can subset to just the species analysed
Max_tss  = as.data.frame(Max_tss)
setDT(Max_tss, keep.rownames = TRUE)[]
Max_tss  = as.data.frame(Max_tss)
names(Max_tss)[names(Max_tss) == 'rn'] <- 'searchTaxon'



## Remove extra text
Max_tss$searchTaxon = gsub("//",         "", Max_tss$searchTaxon)
Max_tss$searchTaxon = gsub(results_dir,   "", Max_tss$searchTaxon)
Max_tss$searchTaxon = gsub("/full/species_omission.csv.Max_tss", "", Max_tss$searchTaxon)
Max_tss$searchTaxon = gsub("/",          "", Max_tss$searchTaxon)
head(Max_tss)


## Add max TSS to the results table
MAXENT.RESULTS = join(MAXENT.RESULTS, Max_tss)
summary(MAXENT.RESULTS$Max_tss)
summary(MAXENT.RESULTS$Omission_rate)


## This is a summary of maxent output for current conditions
## All species should have AUC > 0.7
dim(MAXENT.RESULTS)
head(MAXENT.RESULTS, 20)[1:5]





#########################################################################################################################
## Plot AUC vs. TSS
# if (nrow(MAXENT.RESULTS) > 2) {

# lm.auc = lm(MAXENT.RESULTS$Max_tss ~ MAXENT.RESULTS$Training_AUC)

# ## Save this to file
# png(paste0('./output/maxent/', 'Maxent_run_summary_', save_run, '.png'), 16, 12, units = 'in', res = 500)

# layout(matrix(c(1,1,2,3), 2, 2, byrow = TRUE))

# plot(MAXENT.RESULTS$Training_AUC, MAXENT.RESULTS$Max_tss, pch = 19, col  = "blue",
# xlab = "AUC", ylab = "TSS", 
# abline(lm(MAXENT.RESULTS$Max_tss ~ MAXENT.RESULTS$Training_AUC)), 
# main = save_run, cex = 3)

# legend("topleft", bty = "n", 
# legend = paste("R2 is", format(summary(lm.auc)$adj.r.squared, digits = 4)))

# hist(MAXENT.RESULTS$Training_AUC, breaks = 10, col = "blue",   border = FALSE,
# ylab = "Frequency",
# xlab = "Training AUC", main = "AUC", cex = 3)
# hist(MAXENT.RESULTS$Max_tss,      breaks = 10, col = "orange", border = FALSE,
# ylab = "",
# xlab = "Maximum True Skill Statistic", main = "TSS", cex = 3)

# ## Finsish the device
# dev.off()

# ## If the species list is < 2 records, don't plot
# } else {

# message('Dont plot, only ', length(GBIF.spp), ' species analysed')

# }


#########################################################################################################################
## Now check the match between the species list, and the results list. 
length(intersect(map_spp_list, MAXENT.RESULTS$searchTaxon)) 
MAXENT.RESULTS  =  MAXENT.RESULTS[MAXENT.RESULTS$searchTaxon %in% map_spp_list , ] 
map_spp         = unique(MAXENT.RESULTS$searchTaxon)
length(map_spp);setdiff(sort(map_spp_list), sort(map_spp))


#########################################################################################################################
## Then make a list of all the directories containing the individual GCM rasters. This is used for combining the rasters
SDM.RESULTS.DIR <- map_spp %>%
  
  ## Pipe the list into lapply
  lapply(function(species) {
    
    ## Create the character string...
    m <-   sprintf('%s/%s/full/', results_dir, species)                ## path.backwards.sel
    m
    
  }) %>%
  
  ## Bind the list together
  c()

length(SDM.RESULTS.DIR)
SDM.RESULTS.DIR = unlist(SDM.RESULTS.DIR)


# ## Change the species column
# MAXENT.RESULTS$searchTaxon = gsub("_", " ", MAXENT.RESULTS$searchTaxon)


#########################################################################################################################
## Save maxent results 
# if(save_data == "TRUE") {

# ## save .rds file for the next session
# saveRDS(MAXENT.RESULTS,   paste0(DATA_path, 'MAXENT_RESULTS_', save_run, '.rds'))
# write.csv(MAXENT.RESULTS, paste0(DATA_path, 'MAXENT_RESULTS_', save_run, '.csv'), row.names = FALSE)


# } else {

# message('Dont save niche summary, only ', length(GBIF.spp), ' species analysed')

# }


#########################################################################################################################
## OUTSTANDING SDM TASKS:
#########################################################################################################################


## 1). Check the code can be run through katana


#########################################################################################################################
#####################################################  TBC ############################################################## 
#########################################################################################################################
