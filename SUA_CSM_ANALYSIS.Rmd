---
title: "Substantial declines in urban tree habitat predicted under climate change"
authors: "Hugh Burley, John Baumgartner, Linda Beaumont"
date: "December 2018"
output:
html_document: default
pdf_document: default
---

\


This R markdown file summarises Hugh's contribution to the 'Which Plant Where' project at Macquarie University, 
outlining the key functions I have created during my post doctoral work. WPW is part of the Green Cities
co-investment fund : 

\

https://horticulture.com.au/co-investment-fund/green-cities-fund/


https://www.whichplantwhere.com.au/ 

\


The text and code below summarises a workflow in R that can be used to relatively rapidly assess the effect
of climate change on a given plant within Australia, from downloading occurrence records, through to creating
maps of predicted climatic suitability across Australia at 1km*1km resolution. This work is published in Science 
of the Total Environment ::

\

Burley, H., Beaumont, L.J., Ossola, A., et al. (2019) Substantial declines in urban tree habitat predicted 
under climate change. Science of The Total Environment, 685, 451-462.

https://www.sciencedirect.com/science/article/pii/S0048969719323289#f0030 

\

#########################################################################################################
# **<span style="color:blue"> Summary </span>**
#########################################################################################################

\

**Aim:** Globally, local government authorities are increasing their investment in urban greening 
interventions, yet there is little consideration of whether the current palette of species for these 
plantings will be resilient to climate change. We assessed the distribution of climatically suitable 
habitat, now and in the future, for 176 of the tree species most commonly grown by nurseries and 
planted across Australia's urban landscapes. 

**Location:** Australian Significant Urban Areas 

**Time period:** 1960 - 2070

**Major taxa analysed:** 176 commonly planted and sold horticultural tree species

**Methods:** Species’ occurrence records were obtained from myriad inventories and herbaria, 
both globally and across Australia, along with baseline climate data (WorldClim, 1960-1990) 
and six climate scenarios for 2030 and 2070. Climatic suitability models (CSMs) for each 
species were calibrated and projected onto baseline and future climate scenarios. We 
calculated changes to the size of climatically suitable habitat across SUAs, for each 
species, and identified urban areas that are likely to have suitable climate for fewer 
or more of our study species as climate changes.

**Results:** By 2070, climatically suitable habitat in urban regions is projected 
to decline for ~73% of species, while for 18% of species, suitable climate is predicted 
to decline to less than half of its baseline extent. Generally, urban areas in cooler 
regions are predicted to gain more species than they lose, while urban areas in warmer 
regions may lose more species than they gain. Our results highlight changing patterns 
of urban climatic space for different species, indicating that governments and nurseries 
should take a proactive approach –  utilizing multiple lines of evidence (modelling and 
experiments) – to identify new planting opportunities. 


\


#########################################################################################################
# **<span style="color:blue"> Intro </span>**
#########################################################################################################

\

Globally, government authorities are placing great emphasis on the environmental and socio-economic importance 
of urban trees and vegetation (Luttik, 2000; Chiesura, 2004). In particular, planting trees is increasingly
considered a cost-effective method for improving the adaptability and sustainability of cities to projected 
changes in climate (Espeland and Kettenring, 2018). Trees can further mitigate urban environmental issues that 
will likely be exacerbated by climate change, such as the urban heat island effect [UHI, Norton et al., 2015; 
Lanza and Stone, 2016] and air pollution (Grote et al., 2016; Livesley et al., 2016). As a consequence of these 
benefits, local authorities are increasing their investment in planting as well asmonitoring tree and forest 
assets across urban environments (Endreny, 2018).

\

Despite these financial commitments, there is little consideration of whether the current selection of species 
commonly used in urban plantings will be resilient to changes in climate projected to occur throughout the 
lifespan of each tree species (Ordóñez and Duinker, 2015), which may be decades to a century. Thus, as 
temperatures continue to rise in the 21st century, urban forestry and planning efforts must identify species
that are most likely to thrive in future climates, to maximise planting success and return on investment 
in the long term.

\

In this study, we assessed the baseline (1960–1990), short term (2030) and long term(2070) distribution of 
climatically suitable habitat for 176 native Australian tree species that are commonly planted across
Australia's urban landscapes and are also currently sold in commercial plant nurseries. These species are 
a representative sample of the continent's urban tree flora, and thus are indicative of how urban trees
may fare under climate change. In doing so, we asked: 1) which tree species are more likely to experience 
increases and decreases in the distribution of climatically suitable habitat across urban areas in the short
(2030) and long term(2070); and 2)which urban areas are more likely to experience substantial increases or 
decreases in the number of species with suitable habitat by 2030 and 2070? We expect that urban areas in 
cooler regions will experience greater gains in the number of species with climatically suitable habitat 
than urban areas in warmer regions, consistent with findings from previous studies modelling large suites 
of species occurring in natural environments on the Australian continent [e.g. O'Donnell et al., 2012]. 
We also identify key challenges associated with the use of CSMs for species in urban environments, and 
further discuss the implications for urban forestry, planning and industry efforts in order to create
future urban forests that are more resilient to climate change.

\

#########################################################################################################
### **Defining significant Urban Areas** 
Our spatial units for estimating species' climatic suitability are Australia's Significant Urban Areas 
(SUAs). SUAs are defined by the Australian Bureau of Statistics (ABS) as containing at least 10,000 people
within a single labour market (ABS, 2018). The boundaries for these SUAs were obtained from the Australian 
Bureau of Statistics (ABS, 2018) and refer to the year 2016. Combined, the 82 SUAs span ~46,211 km2, and 
range in size from ~46 km2 (City of Sale, Victoria) to 6189 km2 (City of Melbourne, Victoria).


\newpage 
![](output/figures/CV_figs/FIG1_SUA_PLOTS_NO_SHP.png)

**Figure 1.** Map of 82 Australian Significant Urban Areas (SUA, plotted in pink) included in this study, 
with the largest SUA in each state and territory plotted in blue symbols. According to the Köppen classification 
of Kriticos et al. (2012), all these SUAs fall within ‘temperate’ zones. (For interpretation of the references 
to color in this figure legend, the reader is referred to the web version of this article.)

\

#########################################################################################################
## **Species selection**
To analyse horticulturally significant Australian species, we obtained a list of native tree species 
grown by the nursery industry across Australia, as well as the number of nurseries growing each species 
within each state or territory. We then created a spatial database of urban tree inventories in Australia 
by contacting local government authorities. This resulted in inventory data for 41 local government areas 
spanning  20 SUAs. The 400 most frequently reported trees within the inventories were then intersected 
with the nursery list (i.e. those trees currently being sold within any Australian nursery), creating 
a list of 248 native species. We consider these 248 species as the most commonly planted and sold native 
trees in the current Australian horticultural market. This species list was first checked against the 
backbone taxonomy of the Global Biodiversity Information Facilty (GBIF, www.gbif.org), and then against 
The Plant List (TPL) backbone taxonomy using the Taxonstand package [version 2.1, Cayuela et al (2012)] 
in the R language [Version 3.5.1, R Core team (2018)]. The accepted names from the TPL taxonomy were then 
used for this analysis. 

\

```{r message=FALSE, echo=FALSE, warning=FALSE}

########################################################################################################
## List of Variables used to run the SDM analyses
source('./R/RMD_READ_PACKAGES.R')

```

\

#########################################################################################################
## **Occurrence data** 
For each of these planted and sold species, we downloaded global occurrence records from GBIF and the 
Atlas of Living Australia (ALA, www.ala.org.au) using the rgbif and ALA4R packages in R 
[https://github.com/AtlasOfLivingAustralia/ALA4R, (Hijmans et al. 2016) (R Core Team, 2017), 
see R script "1_GBIF_ALA_DOWNLOAD.R"]. We then undertook an intensive spatial data-cleaning process to 
remove spatially invalid or suspect records that, if retained, can cause species' climate niches to be 
miscalculated (R scripts 2-6). Spatially invalid records, those collected before 1950, duplicate records, 
those records within 10 km of capital cities (which are likely to be herbarium records, and thus not 
reflective of the species realised niche), herbaria and biodiversity institutions, and individual 
records 300 km from other records for that species were removed using the CoordinateCleaner package 
[Zizka et al., 2019, version 1.0–7, resulting in ~22% of ~ 2.2 million records for 248 species being removed].

\

The backbone of the R workflow is a list of plant species. It is designed to download occurrence data for
that list of species, clean it for common errors with a series of filters (taxonomic, contextual, spatial), 
extract the climatic conditions for all records, and finally format the records into a table that can be
passed to the Maxent algorithm (see 'H:\green_cities_sdm\output\maxent\SUA_SDM_analysis_workflow.pptx').   

\

#########################################################################################################
## **Climate data**
We obtained baseline climate data from the WorldClim Database [worldclim.org/bioclim, Version 1.4 
(Hijmans et al. 2005)]. WorldClim comprises 19 bioclimatic variables, summarised for the period 1960-1990, 
of which we used eight for model calibration: Annual mean temperature, Temperature seasonality, 
Maximum temperature of the warmest month, Minimum temperature of the coldest month, Annual precipitation, 
Precipitation seasonality, Precipitation of the wettest month, and Precipitation of the driest month. 
These variables were chosen to capture climate averages, seasonality and extremes, all of which have 
been identified as important variables for predicting suitable habitat for plants (Bradie & Leung, 2017).
Importantly, when averaged across the species analysed, the tree inventory data shows the urban climate niche 
(quantified using tree inventory records) is effectively a subset of the ‘natural’ niche (quantified using 
occurrence records fromGBIF and ALA, see Appendix, Fig. S1). 

\newpage 
![](output/figures/CV_figs/Niche_overlap.png)

**Figure S1.** Convex hull plot of current (1960-1990) annual rainfall and mean annual temperature, 
using the spatial data for all 176 native Australian trees in our analysis. ‘OCC’ denotes 
occurrence data from GBIF and ALA (blue points and convex hull), while ‘INV’ denotes data 
from the tree inventories (red points and convex hull).

\

When assessing the impacts of climate change, it is more robust to use projections from multiple climate 
models (IPCC, 2014; Taylor, Stouffer, & Meehl, 2011; Beaumont et al. 2007, Baumgartner et al 2018). We 
utilised a subset of six models recommended by CSIRO's Climate Change in Australia report 
(https://www.climatechangeinaustralia.gov.au/en/), as these models were shown to perform better than others 
in their ability to simulate historical Australian climate. Hence, more confidence can be placed 
in their projections of future climate. For each of these six GCMs, we downloaded monthly maximum and 
minimum temperature and monthly precipitation from CSIRO for 2030, 2050 and 2070, at a spatial resolution 
of 30 arc-seconds (~1 km). From these data, we calculated the eight bioclimatic variables for the three 
time periods and re-projected the data to an equal area grid of 1 km x 1 km resolution to match the baseline 
climate, using R [version 3.4.2, R Core Team (2017)]. 

\

#########################################################################################################
## **Modeling approach**
We modelled climatic suitability under current conditions (1960-1990) using the Maxent algorithm 
(Elith et al. 2011; Phillips et al. 2006; Phillips and Dudik 2008) within the Dismo R package 
(Hijmans et al. 2016). Maxent is a machine learning, correlative approach to modelling climatic suitability 
that is generally regarded as superior to other algorithms that are used to model presence-only 
occurrence data (Elith et al. 2006). Models were calibrated using most of the default Maxent settings, 
although hinge and threshold ‘features’ [mathematical transformations/simplifications of predictor variables, 
Elith et al., 2011] were disabled to reduce over-fitting the models. In addition to occurrence records, 
Maxent requires ‘background’ data that characterise the surrounding environment in which the modelled 
species occurs. Our background points comprised random samples of up to 70,000 cells from the pool of 
cells that (a) contained occurrence records in ALA for one or more plant species, (b) fell within 200 km 
of records for the target species[i.e. a buffered target-group background, Elith and Leathwick, 2007;Phillips 
and Dudík, 2008], and (c) were within the same Köppen climate zone as the modelled species' known 
occurrences [using the Köppen classification from Kriticos et al., 2012]. This approach was utilised to
ensure that both the occurrence and background points had similar spatial
biases, a key requirement for improving Maxent model calibration.

\

To run models for all species in the list, we created a function in the R programming language which splits 
a table of all species records * environmental conditions (the outcome of R scripts 1-6) into only those 
spatial records for a given species, and calibrates a Maxent model under current climate for that species.
The background points in this function are simply any record in the maxent table which is not the species
being modelled. This means the maxent table must be large for a big list of taxa (e.g plants and animals).
This is a limitation of the current workflow, but is suitable for processing smaller sets of species
(i.e. several hundred, or a few thousand).

\

This function runs two maxent models :: one using all the predictor variables supplied, and one which uses 
variance inflation factors (VIF) to run backwards selection on the full model. Given a candidate set of predictor 
variables (e.g. climate, soil, etc.) , this function identifies a subset that meets specified multicollinearity 
criteria. Subsequently, backward stepwise variable selection (VIF) is used to iteratively drop the variable that 
contributes least to the model, until the contribution of each variable meets a specified minimum, or until 
a predetermined minimum number of predictors remains. While this function is memory intensive, it is very useful 
to screen a large number of potentially useful but strongly correlated GIS layers (e.g. interpolated layers 
which are all based on similar input data, such as digital elevation models, meteorological stations or soil samples).


```{r run maxent, eval = FALSE, echo = TRUE}

#########################################################################################################
## A function which splits a table of species records * environmental conditions into records for each 
## species, then fits a maxent model under current climatic conditions, and runs backwards selection
lapply(GBIF.spp, function(spp){ 
  
  ## Skip the species if the directory already exists, before the loop
  outdir <- maxent_dir
  
  if(dir.exists(file.path(maxent_path, gsub(' ', '_', spp)))) {
    message('Skipping ', spp, ' - already run.')
    invisible(return(NULL))
    
  }
  
  ## Print the taxa being processed to screen
  if(spp %in% SDM.SPAT.ALL$searchTaxon) {
    message('Doing ', spp) 
    
    ## Subset the records to only the taxa being processed
    occurrence <- subset(SDM.SPAT.ALL, searchTaxon == spp)
    
    ## Now get the background points. These can come from any spp, other than the modelled species.
    background <- subset(SDM.SPAT.ALL, searchTaxon != spp)
    
    ## Finally fit the models using FIT_MAXENT_TARG_BG. 
    tryCatch(
      fit_maxent_targ_back(occ                     = occurrence,  ## occurrence points
                           bg                      = background,  ## background points
                           sdm.predictors          = sdm.select,  ## predictor variables
                           name                    = spp,         ## Species name
                           outdir,                                ## Output directory
                           bsdir                   = bs_dir,      ## Store BS results
                           
                           backwards_sel           = "TRUE",
                           cor_thr                 = 0.8,         ## Max pairwise correlation 
                           pct_thr                 = 5,           ## Min percent contribution
                           k_thr                   = 4,           ## Min number of variables
                           
                           template.raster,                       ## Resolution raster
                           min_n                   = 20,          ## Minimum records           
                           max_bg_size             = 70000,       ## Max bg points
                           Koppen                  = Koppen_1975, ## Koppen Shapefile 
                           background_buffer_width = 200000,      ## Km
                           shapefiles              = TRUE,        ## Save bg and occ shp?
                           features                = 'lpq',       ## Maxent features
                           replicates              = 5,           ## No. of K-fold
                           responsecurves          = TRUE),       ## save response curves?
      
      error = function(cond) {

        message(paste('Species skipped ', spp))

      })
    
  } else {
    
    message(spp, ' skipped - no data.')   
    
  }  
  
})


```

\


```{r eval = FALSE, echo = TRUE}

## Print the maxent function
fit_maxent_targ_bg_back_sel <- function(occ,
                                        bg, # 
                                        sdm.predictors,
                                        name,
                                        outdir,
                                        bsdir,
                                        cor_thr,                 
                                        pct_thr, 
                                        k_thr,
                                        
                                        backwards_sel,
                                        template.raster,
                                        min_n,

                                        max_bg_size,
                                        background_buffer_width, 
                                        Koppen,
                                        shapefiles,
                                        features,
                                        replicates, 
                                        responsecurves,
                                        rep_args,
                                        full_args,
                                        shp_path, 
                                        aus_shp) {
  
  ########################################################################
  ## First, stop if the outdir file exists,
  if(!file.exists(outdir)) stop('outdir does not exist :(', call. = FALSE)
  outdir_sp <- file.path(outdir, gsub(' ', '_', name))
  bsdir_sp  <- file.path(bsdir,  gsub(' ', '_', name))
  
  if(!missing('Koppen')) {
    if(!is(Koppen, 'RasterLayer'))
      stop('Koppen must be a RasterLayer, and should be in the same coordinate system as template.raster')  
  }

  ## If the file doesn't exist, split out the features
  if(!file.exists(outdir_sp)) dir.create(outdir_sp)
  features <- unlist(strsplit(features, ''))
  
  ## Make sure user features are allowed: don't run the model if the
  ## features have been incorrectly specified in the main argument
  ## l: linear
  ## p: product
  ## q: quadratic
  ## h: hinge       ## disabled for this analysis
  ## t: threshold   ## disabled for this analysis
  if(length(setdiff(features, c('l', 'p', 'q', 'h', 't'))) > 1)
    stop("features must be a vector of one or more of ',
         'l', 'p', 'q', 'h', and 't'.")
  
  ## Create a buffer of xkm around the occurrence points
  buffer <- aggregate(gBuffer(occ, width = background_buffer_width, byid = TRUE))
  
  #####################################################################
  ## Get unique cell numbers for species occurrences
  cells <- cellFromXY(template.raster, occ)

  ## Clean out duplicate cells and NAs (including points outside extent of predictor data)
  ## Note this will get rid of a lot of duplicate records not filtered out by GBIF columns, etc.
  not_dupes <- which(!duplicated(cells) & !is.na(cells))
  occ       <- occ[not_dupes, ]
  cells     <- cells[not_dupes]
  message(nrow(occ), ' occurrence records (unique cells).')
  
  #####################################################################
  ## Skip species that have less than a minimum number of records: eg 20 species
  if(nrow(occ) < min_n) {
    
    print (paste ('Fewer occurrence records than the number of cross-validation ',
                  'replicates for species ', name,
                  ' Model not fit for this species'))
    
  } else {
    
    #####################################################################
    ## Subset the background records to the 200km buffered polygon
    message(name, ' creating background cells')
    system.time(o <- over(bg, buffer))
    bg <- bg[which(!is.na(o)), ]
    bg_cells <- cellFromXY(template.raster, bg)
    
    ## Clean out duplicates and NAs (including points outside extent of predictor data)
    bg_not_dupes <- which(!duplicated(bg_cells) & !is.na(bg_cells))
    bg           <- bg[bg_not_dupes, ]
    bg_cells     <- bg_cells[bg_not_dupes]
    
    ## Find which of these cells fall within the Koppen-Geiger zones that the species occupies
    ## Crop the Kopppen raster to the extent of the occurrences, and snap it
    message(name, ' intersecting background cells with Koppen zones')
    Koppen_crop <- crop(Koppen, occ, snap = 'out')
    
    ## Only extract and match those cells that overlap between the ::
    ## 1). cropped koppen zone, 
    ## 2). occurrences and 
    ## 3). background points 
    message(xres(template.raster), ' metre cell size for template raster')
    message(xres(Koppen), ' metre cell size for Koppen raster')
    zones               <- raster::extract(Koppen_crop, occ)
    cells_in_zones_crop <- Which(Koppen_crop %in% zones, cells = TRUE)
    cells_in_zones      <- cellFromXY(Koppen, xyFromCell(Koppen_crop, cells_in_zones_crop))
    bg_cells            <- intersect(bg_cells, cells_in_zones)  ## this is 0 for 5km 
    i                   <- cellFromXY(template.raster, bg)
    bg                  <- bg[which(i %in% bg_cells), ]
       
    #####################################################################
    ## Get the proportion of occurrence records from each source 
    source.prop = round(with(as.data.frame(occ), table(SOURCE)/sum(table(SOURCE))), 3)
    ala.prop    = sum(source.prop["ALA"], source.prop["GBIF"], na.rm = TRUE)
    inv.prop    = source.prop["INVENTORY"]
    
    ## Reduce background sample, if it's larger than max_bg_size
    if (nrow(bg) > max_bg_size) {
      
      message(nrow(bg), ' target species background records for ', name, 
              ', reduced to random ', max_bg_size, ' using random points from :: ', unique(bg$SOURCE))
      bg.samp <- bg[sample(nrow(bg), max_bg_size), ]
      
    } else {
      
      ## If the bg points are smaller that the max_bg_size, just get all the points
      message(nrow(bg), ' target species background records for ', name, 
              ' using all points from :: ', unique(bg$SOURCE))
      bg.samp <- bg
      
    }
      
    #####################################################################
    ## Now save the buffer, the occ and bg points as shapefiles
    if(shapefiles) {
      
      suppressWarnings({
        
        message(name, ' writing occ and bg shapefiles')
        writeOGR(SpatialPolygonsDataFrame(buffer, data.frame(ID = seq_len(length(buffer)))),
                 outdir_sp, paste0(save_name, '_bg_buffer'),          'ESRI Shapefile', overwrite_layer = TRUE)
        writeOGR(bg.comb,  outdir_sp, paste0(save_name, '_bg'),       'ESRI Shapefile', overwrite_layer = TRUE)
        writeOGR(occ,           outdir_sp, paste0(save_name, '_occ'), 'ESRI Shapefile', overwrite_layer = TRUE)
        
      })
      
    }
    
    ## Also save the background and occurrence points as .rds files
    saveRDS(bg.comb,  file.path(outdir_sp, paste0(save_name, '_bg.rds')))
    saveRDS(occ,      file.path(outdir_sp, paste0(save_name, '_occ.rds')))
    
    #####################################################################
    ## SWD = species with data. Now sample the environmental 
    ## variables used in the model at all the occ and bg points
    swd_occ <- occ[, sdm.predictors]
    saveRDS(swd_occ, file.path(outdir_sp, paste0(save_name,'_occ_swd.rds')))
    
    swd_bg <- bg.comb[, sdm.predictors]
    saveRDS(swd_bg, file.path(outdir_sp, paste0(save_name, '_bg_swd.rds')))
    
    ## Save the SWD tables as shapefiles
    if(shapefiles) {
      
      writeOGR(swd_occ, outdir_sp,  paste0(save_name, '_occ_swd'), 'ESRI Shapefile', overwrite_layer = TRUE)
      writeOGR(swd_bg,  outdir_sp,  paste0(save_name, '_bg_swd'),  'ESRI Shapefile', overwrite_layer = TRUE)
      
    }
    
    #####################################################################
    ## Now combine the occurrence and background data
    swd <- as.data.frame(rbind(swd_occ@data, swd_bg@data))
    saveRDS(swd, file.path(outdir_sp, 'swd.rds'))
    pa  <- rep(1:0, c(nrow(swd_occ), nrow(swd_bg)))
    
    ## Now, set the features to be used by maxent ::
    ## Linear, product and quadratic
    off <- setdiff(c('l', 'p', 'q', 't', 'h'), features)
    
    ## This sets threshold and hinge features to "off"
    if(length(off) > 0) {
      
      off <- c(l = 'linear=false',    p = 'product=false', q = 'quadratic=false',
               t = 'threshold=false', h = 'hinge=false')[off]
      
    }
    
    off <- unname(off)
    
    if(replicates > 1) {
      
      if(missing(rep_args)) rep_args <- NULL
      
      ## Run MAXENT for cross validation data splits of swd : so 5 replicaes, 0-4
      ## first argument is the predictors, the second is the occurrence data
      message(name, ' running xval maxent')
      me_xval <- maxent(swd, pa, path = file.path(outdir_sp, 'xval'),
                        args = c(paste0('replicates=', replicates),
                                 'responsecurves=true',
                                 'outputformat=logistic',
                                 off, paste(names(rep_args), rep_args, sep = '=')))
      
    }
    
    ## Run the full maxent model - using all the data in swd
    ## This uses DISMO to output standard files, but the names can't be altered
    if(missing(full_args)) full_args <- NULL
    message(name, ' running full maxent')
    me_full <- maxent(swd, pa, path = file.path(outdir_sp, 'full'),
                      args = c(off, paste(names(full_args), full_args, sep = '='),
                               'responsecurves=true',
                               'outputformat=logistic'))
    
    ## Save the full model. Replicate this line in the backwards selection algortithm
    ## This is needed to project the models.........................................
    ## Also worth checking that the koppen zones can be used at any resolution
    saveRDS(list(me_xval = me_xval, me_full = me_full, swd = swd, pa = pa, 
                 koppen_gridcode=as.character(Koppen_zones$Koppen[match(unique(zones), Koppen_zones$GRIDCODE)])), 
            file.path(outdir_sp, 'full', 'maxent_fitted.rds'))
    
    if (backwards_sel == "TRUE") {
      
      #####################################################################
      ## Coerce the "species with data" (SWD) files to regular data.frames
      ## This is needed to use the simplify function 
      swd_occ     <- as.data.frame(swd_occ)
      swd_occ$lon <- NULL
      swd_occ$lat <- NULL
      swd_bg      <- as.data.frame(swd_bg)
      swd_bg$lon  <- NULL
      swd_bg$lat  <- NULL
      
      ## Need to create a species column here
      swd_occ$searchTaxon <- name
      swd_bg$searchTaxon  <- name
      
      #####################################################################
      ## Run simplify rmaxent::simplify
      
      # Given a candidate set of predictor variables, this function identifies 
      # a subset that meets specified multicollinearity criteria. Subsequently, 
      # backward stepwise variable selection (VIF) is used to iteratively drop 
      # the variable that contributes least to the model, until the contribution 
      # of each variable meets a specified minimum, or until a predetermined 
      # minimum number of predictors remains. It returns a model object for the 
      # full model, rather than a list of models as does the previous function
      
      ## Using a modified versionof rmaxent::simplify, so that the name of the
      ## maxent model object "maxent_fitted.rds" is the same in both models.
      ## This is needed to run the mapping step over either the full or BS folder
      m <- local_simplify(      
        swd_occ, 
        swd_bg,
        path            = bsdir, 
        species_column  = "searchTaxon",
        replicates      = replicates,  ## 5 as above
        response_curves = TRUE, 
        logistic_format = TRUE, 
        cor_thr         = cor_thr, 
        pct_thr         = pct_thr, 
        k_thr           = k_thr, 
        features        = features,    ## LPQ as above
        quiet           = FALSE)
      
      ## Save the bg, occ and swd files into the backwards selection folder too
      saveRDS(bg.comb,  file.path(bsdir_sp, paste0(save_name, '_bg.rds')))
      saveRDS(occ,      file.path(bsdir_sp, paste0(save_name, '_occ.rds')))
      saveRDS(swd,      file.path(bsdir_sp, paste0('swd.rds')))
      
      ## Read the model in, because it's tricky to index
      bs.model <- readRDS(sprintf('%s/%s/full/maxent_fitted.rds', bsdir,  save_name))
      identical(length(bs.model@presence$Annual_mean_temp), nrow(occ))
	  
    } else {
      
      message("Don't run backwards selection")
      
    }
    
  }
  
}

```

\

The performance of each model was estimated by calculating the average Area Under the Receiver Operating 
Characteristic curve (Swets,1988) and the True Skill Statistic (TSS) on test data through five-fold
cross-validation. This involved splitting the occurrence data for each species into five random subsets 
of close to equal size (i.e. folds), fitting the model to four of the five folds and predicting to the fifth. 
This process was repeated until each fold was used four times for model fitting and once for model evaluation 
(Stone, 1974, see plot and table below for example species). Subsequently, CSMs were fitted a final time using 
the complete set of species data. It is important to emphasize that models can have high performance indicators 
with respect to test/training data, yet still over-project suitability (i.e. although the model projects some 
cells to be suitable, given ecological knowledge of the species these cells are unlikely to be suitable in reality). 
This may indicate that models are encountering novel conditions. To explore this, we calculated Multivariate 
Environmental Similarity Surfaces [MESS, Elith et al., 2010; Baumgartner et al. (2017)]. Although MESS maps indicated 
that the models were not projecting to novel states for individual variables, this approach does not consider 
novel combinations of variables. An alternate explanation for over-projection is that suitable conditions 
for the species are influenced by environmental variables not considered in the model [such as edaphic 
conditions, see Barry and Elith, 2006]. 

\

```{r maxent table, message = FALSE, echo = FALSE, warning = FALSE}
source('./R/COLLATE_MAXENT_KATANA_RESULTS.R',   echo = FALSE)
kable(head(MAXENT.RESULTS[1:3, 10:15], 10))

```

\

As such, we visually assessed all maps of current suitable habitat (e.g. Fig 2), and excluded from our analysis models 
whose resulting maps contained substantial over projection.Although this approach is somewhat subjective, 
excluding questionable models in this way adds more rigour to our analysis than if we were to rely solely 
on AUC and TSS values. This expert validation procedure suggested that for 72 species, additional/alternative 
climate variables (beyond the readily available bioclimatic variables)may be required in order to adequately 
characterise the species' realised climate niche. Hence, the following results are based on data for the 
remaining 176 species with robust models only. The CSM for each of these species was projected onto the 
six climate scenarios for two future time periods (2030 and 2070), using the project function in the rmaxent 
package [https://github.com/johnbaums/rmaxent; Baumgartner et al., 2017].

\

#########################################################################################################
## **Projecting the models to future scenarios**
We then created a function to take the maxent model for each species, and project it onto the six chosen 
climate scenarios for three future time periods (2030, 2050 and 2070), using the 'Rmaxent' package.
This function loops over all 6 climate scenarios for each species analysed, one period at a time 
(2030/50/70).

\

```{r, eval=FALSE, echo=TRUE}

## A function which projects climatic suitability under six GCMs at each time step (2030/50/70)
tryCatch(
  project_maxent_grids_mess(shp_path      = "./data/base/CONTEXTUAL/", ## Path for shapefile
                            aus_shp       = "aus_states.rds",          ## Shapefile
                            world_shp     = "LAND_world.rds",          ## World shapefile          
                            
                            scen_list     = scen_2030,                 ## Scenario list
                            species_list  = map_spp,                   ## Species folder list
                            maxent_path   = bs_path,                   ## Output folder
                            climate_path  = "./data/climate",          ## Climate path
                            
                            grid_names    = grid.names,                ## Predictor variable names
                            time_slice    = 30,                        ## Time period
                            current_grids = aus.grids.current,         ## Predictor grids 
                            create_mess   = "TRUE",
                            nclust        = 1),
  
  ## If the species fails, write a fail message to file. 
  error = function(cond) {
    
    ## This will write the error message inside the text file, 
    ## but it won't include the species
    file.create(file.path(bs_path, "mapping_failed_2030.txt"))
    cat(cond$message, file=file.path(bs_path, "mapping_failed_2030.txt"))
    warning(cond$message)
    
  })

```

\

This function also runs Multivariate environmental similarity (MESS) maps for each species. MESS maps measure 
the similarity between the new environments, and those in the training sample. When model predictions are 
projected into regions, times or spatial resolutions not analysed in the training data, it is important 
to measure the similarity between the new environments, and those in the training sample (Elith et al. 2010), 
as models are unreliable when predicting outside their domain (Barbosa et al. 2009). This process is 
especially important for interpreting the results for taxa which have been reliably recorded across large 
geographic and environmental ranges (e.g. for plant species that have wide distributions both in their 
country of 'origin', and throughout the world).

\

```{r eval = FALSE, echo = TRUE}

## Run the project function for each time period separately
project_maxent_grids_mess = function(shp_path, aus_shp, world_shp, scen_list, 
                                     species_list, maxent_path, climate_path, 
									 static_path,  grid_names, time_slice, 
									 current_grids, create_mess, nclust) {
  
  ## Read in the Australian shapefile at the top
  aus_poly = readRDS(paste0(shp_path, aus_shp)) %>%
    spTransform(ALB.CONICAL)
  
  world_poly = readRDS(paste0(shp_path, world_shp)) %>%
    spTransform(CRS.WGS.84)
  
  ###########################################
  ## First, run a loop over each scenario:    
  lapply(scen_list, function(x) {
    
    ## Create a raster stack for each of the 6 GCMs, not for each species
    ## They need to have exactly the same extent.
    ## Could stack all the rasters, or, keep them separate
    s <- stack(c(sprintf('%s/20%s/%s/%s%s.tif', climate_path, time_slice, x, x, 1:19)))#
    
    ## Note this step is only needed if the current grids used in the their original form, rather than being renamed...............
    names(s) <- names(current_grids) <- grid_names 
    
    ########################################################################################################################
    ## Divide the 11 temperature rasters by 10: NA values are the ocean
    ## s[[1:11]] <- s[[1:11]]/10 ## That code doesn't work
    message('First, divide the raster stack for ', x, ' by 10 ')
    for(i in 1:11) {
      ## Simple loop
      message(i)
      s[[i]] <- s[[ i]]/10
      
    }
    
    ## Then apply each GCM to each species.
    ## First, check if the maxent model exists
    ## Then apply each GCM to each species
    ## Define function to then send to one or multiple cores
    maxent_predict_fun <- function(species) {
      
      #############################################
      save_name = gsub(' ', '_', species)
      if(file.exists(sprintf('%s/%s/full/maxent_fitted.rds', maxent_path, species))) {
        message('Then run maxent projections for ', species, ' under ', x, ' scenario')
        
        ## Then, check if the species projection has already been run...
        if(!file.exists(sprintf('%s/%s/full/%s_future_not_novel_%s.tif', maxent_path, species, species, x))) {
          
          ########################################################################
          ## Now read in the SDM model, calibrated on current conditions
          ## if it was run with backwards selection, just use the full model
          if (grepl("BS", maxent_path)) {
            
            message('Read in the BS model')
            m   <- readRDS(sprintf('%s/%s/full/maxent_fitted.rds', maxent_path, species)) 
            
          } else {
            
            ## Otherwise, index the full model
            message('Read in the full model')
            m   <- readRDS(sprintf('%s/%s/full/maxent_fitted.rds', maxent_path, species))$me_full
            
          }
          
          ## Read in the swd object and occurrence data
          swd <- as.data.frame(readRDS(sprintf('%s%s/swd.rds',    maxent_path, species, species)))
          occ <- readRDS(sprintf('%s%s/%s_occ.rds', maxent_path, species, save_name)) %>%
            spTransform(ALB.CONICAL)  
          
          ## Create a file path for the current raster prediction
          f_current  <- sprintf('%s%s/full/%s_current.tif', maxent_path, species, species)
          
          ## If the current raster prediction has not been run, run it
          if(!file.exists(f_current)) {
            
            ## Report which prediction is in progress :: m$me_full, m$me_full@presence
            message('Running current prediction for ', species) 
            
            pred.current <- rmaxent::project(
              m, current_grids[[colnames(m@presence)]])$prediction_logistic
            writeRaster(pred.current, f_current, overwrite = TRUE)
            
          } else {
            message('Use existing prediction for ', species)                   ## Can get rid of this
            pred.current = raster(sprintf('%s/%s/full/%s_current.tif',
                                          maxent_path, species, species))
          }
          
          #####################################################################
          ## Report current mess map in progress
          MESS_dir = sprintf('%s%s/full/%s', 
                             maxent_path, species, 'MESS_output')
          f_mess_current = sprintf('%s/%s%s.tif', MESS_dir, species, "_current_mess")
          
          # if(create_mess == "TRUE" && !file.exists(f_mess_current)) {
          #   message('Running current mess map for ', species)
          
          ## Set the names of the rasters to match the occ data, and subset both
          sdm_vars             = names(m@presence)
          current_grids        = subset(current_grids, sdm_vars)
          swd                  = swd [,sdm_vars]
          identical(names(swd), names(current_grids))
          
          ## Create a map of novel environments for current conditions.
          ## This similarity function only uses variables (e.g. n bioclim), not features
          mess_current  <- similarity(current_grids, swd, full = TRUE)
          novel_current <- mess_current$similarity_min < 0  ##   All novel environments are < 0
          novel_current[novel_current==0] <- NA             ##   0 values are NA
          
          ##################################################################
          ## Write out the current mess maps - 
          ## create a new folder for the mess output 
          if(!dir.exists(MESS_dir)) {
            message('Creating MESS directory for ', species) 
            dir.create(MESS_dir)
            
          } else {        
            message(species, ' MESS directory already created')             
          }
          
          ## Then write the mess output to a directory inside the 'full' maxent folder
          writeRaster(mess_current$similarity_min, sprintf('%s/%s%s.tif', MESS_dir, species, "_current_mess"), 
                      overwrite = TRUE)
          
          ##################################################################
          ## Create a PNG file of MESS maps for each maxent variable
          ## raster_list  = unstack(mess_current$similarity) :: list of environmental rasters
          ## raster_names = names(mess_current$similarity)   :: names of the rasters
          message('Creating mess maps of each current environmental predictor for ', species)
          mapply(function(raster, raster_name) {
            
            ## Create a level plot of MESS output for each predictor variable, for each species
            p <- levelplot(raster, margin = FALSE, scales = list(draw = FALSE),
                           at = seq(minValue(raster), maxValue(raster), len = 100),
                           colorkey = list(height = 0.6), 
                           main = gsub('_', ' ', sprintf('Current_mess_for_%s (%s)', raster_name, species))) +
              
              latticeExtra::layer(sp.polygons(aus_poly), data = list(aus_poly = aus_poly))  ## need list() for polygon
            
            p <- diverge0(p, 'RdBu')
            f <- sprintf('%s/%s%s%s.png', MESS_dir, species, "_current_mess_", raster_name)
            
            png(f, 8, 8, units = 'in', res = 300, type = 'cairo')
            print(p)
            dev.off()
            
          }, unstack(mess_current$similarity), names(mess_current$similarity))
          
          ## Write the raster of novel environments to the MESS sub-directory
          if(!file.exists(sprintf('%s/%s%s.tif', MESS_dir, species, "_current_novel")))  {
            
            message('Writing currently novel environments to file for ', species) 
            writeRaster(novel_current, sprintf('%s/%s%s.tif', MESS_dir, species, "_current_novel"), 
                        overwrite = TRUE)
            
          } else {
            
            message(species, 'Current MESS directory already created') 
            
          }
          
          ##################################################################
          ## Now mask out novel environments
          ## is.na(novel_current) is a binary layer showing 
          ## not novel [=1] vs novel [=0], 
          ## so multiplying this with hs_current will mask out novel
          hs_current_not_novel <- pred.current * is.na(novel_current) 
          
          ## This layer of currently un-novel environments can be used 
          ## for the next algorithm step, where we combine the models
          plot(hs_current_not_novel, main = save_name)
          
          ## Write out not-novel raster :: this can go to the main directory
          message('Writing currently un-novel environments to file for ', species) 
          writeRaster(hs_current_not_novel, sprintf('%s%s/full/%s%s.tif', maxent_path, 
                                                    species, species, "_current_not_novel"),
                      overwrite = TRUE)

          #####################################################################
          ## Create file path for future raster doesn't exist, create it 
          f_future <- sprintf('%s/%s/full/%s_future_not_novel_%s.tif', 
                              maxent_path, species, species, x)
          
          if(!file.exists(f_future)) {
            
            ## Report which prediction is in progress
            message('Running future maxent prediction for ', species, ' under ', x) 
            
            ## Create the future raster
            pred.future <- rmaxent::project(
              m, s[[colnames(m@presence)]])$prediction_logistic
            writeRaster(pred.future, f_future, overwrite = TRUE)
            
            ###################################################################
            ## Report future mess map in progress
            f_mess_future = sprintf('%s/%s%s%s.tif', MESS_dir, species, "_future_mess_", x)
            
            if(create_mess == "TRUE" & !file.exists(f_mess_future)) {
              message('Running future mess map for ', species, ' under ', x)
              
              ## Set the names of the rasters to match the occ data, and subset both
              ## Watch the creation of objects in each run
              sdm_vars             = names(m@presence)
              future_grids         = s
              future_grids         = subset(future_grids, sdm_vars)
              swd                  = swd [,sdm_vars]
              identical(names(swd), names(future_grids))
              
              ## Create a map of novel environments for future conditions
              ## This similarity function only uses variables (e.g. n bioclim), not features.
              ## We don't need to repeat the static layer MESS each time - just
              ## include their results here
              mess_future  <- similarity(future_grids, swd, full = TRUE)
              novel_future <- mess_future$similarity_min < 0  ##   All novel environments are < 0
              novel_future[novel_future==0] <- NA             ##   0 values are NA
              
              ##################################################################
              ## Write out the future mess maps, for all variables
              writeRaster(mess_future$similarity_min, sprintf('%s/%s%s%s.tif', 
			  MESS_dir, species, "_future_mess_", x), 
                          overwrite = TRUE)
              
              ##################################################################
              ## Create a PNG file of all the future MESS output: 
              ## raster_list  = unstack(mess_current$similarity) :: list of environmental rasters
              ## raster_names = names(mess_current$similarity)   :: names of the rasters
              message('Creating mess maps of each future environmental predictor for ', 
			  species, ' under scenario ', x)
              mapply(function(raster, raster_name) {
                
                p <- levelplot(raster, margin = FALSE, scales = list(draw = FALSE),
                               at = seq(minValue(raster), maxValue(raster), len = 100),
                               colorkey = list(height = 0.6), 
                               main = gsub('_', ' ', sprintf('Future_mess_for_%s_%s (%s)', 
							   raster_name, x, species, x))) +
                  
                  latticeExtra::layer(sp.polygons(aus_poly), data = list(aus_poly = aus_poly)) 
                
                p <- diverge0(p, 'RdBu')
                f <- sprintf('%s/%s%s%s%s%s.png', MESS_dir, species, "_future_mess_", raster_name, "_", x)
                
                png(f, 8, 8, units = 'in', res = 300, type = 'cairo')
                print(p)
                dev.off()
                
              }, unstack(mess_future$similarity), names(mess_future$similarity))
              
              ## Write the raster of novel environments to the maxent directory 
              ## The "full" directory is getting full, could create a sub dir for MESS maps
              message('Writing future novel environments to file for ',    species, ' under scenario ', x) 
              writeRaster(novel_future, sprintf('%s/%s%s%s.tif', MESS_dir, species, "_future_novel_",  x), 
                          overwrite = TRUE)
              
              ##################################################################
              # mask out future novel environments 
              # is.na(novel_future) is a binary layer showing 
              # not novel [=1] vs novel [=0], 
              # so multiplying this with hs_future will mask out novel
              hs_future_not_novel <- pred.future * is.na(novel_future)
              
              ## This layer of future un-novel environments can be used 
              ## for the next algorithm step, where we combine the models
              plot(pred.future);plot(hs_future_not_novel)
              summary(pred.future,         maxsamp = 100000);
              summary(hs_future_not_novel, maxsamp = 100000)
              
              ## Write out not-novel raster
              message('Writing un-novel environments to file under ', x, ' scenario for ', species) 
              writeRaster(hs_future_not_novel, sprintf('%s%s/full/%s%s%s.tif', maxent_path, 
                                                       species, species, "_future_not_novel_", x), 
                          overwrite = TRUE)
              
            } else {
              
              message('Dont run future MESS maps for ', species, ' under scenario ',  x ) 
              
            }
            
            ###################################################################
            ## Convert binary rasters of novel climate to polygons
            ## Need to save the polygons to file ::  
            message('Converting raster MESS maps to polygons under ', x, ' scenario for ', species) 
            
            ## If we're on linux, use the standard polygonizer function             
            novel_current_poly <- polygonizer(sprintf('%s/%s%s.tif',   
			MESS_dir, species, "_current_novel"))
            novel_future_poly  <- polygonizer(sprintf('%s/%s%s%s.tif', 
			MESS_dir, species, "_future_novel_", x))

            
            ## Re-project the shapefiles
            novel_current_poly = novel_current_poly %>%
              spTransform(ALB.CONICAL)
            
            novel_future_poly = novel_future_poly %>%
              spTransform(ALB.CONICAL)
            
            ## Now save the novel areas as shapefiles
            MESS_shp_path   = sprintf('%s%s/full/%s', 
                                      maxent_path, species, 'MESS_output')
            
            writeOGR(obj    = novel_current_poly, 
                     dsn    = sprintf('%s',  MESS_shp_path), 
                     layer  = paste0(species, "_current_novel_polygon"),
                     driver = "ESRI Shapefile", overwrite_layer = TRUE)
            
            writeOGR(obj    = novel_future_poly, 
                     dsn    = sprintf('%s',  MESS_shp_path), 
                     layer  = paste0(species, "_future_novel_polygon_", x),
                     driver = "ESRI Shapefile", overwrite_layer = TRUE)
            
            ## Create a SpatialLines object that indicates novel areas (this will be overlaid)            
            ## Below, we create a dummy polygon as the first list element (which is the extent
            ## of the raster, expanded by 10%), to plot on panel 1). 50 = approx 50 lines across the polygon
            message('Creating polygon list under ', x, ' scenario for ', species) 
            
            ## Cast the objects into the sf class
            novel_hatch <- list(as(extent(pred.current)*1.1, 'SpatialPolygons'),
                                hatch(as(novel_current_poly, 'sf'), 50),
                                hatch(as(novel_future_poly,  'sf'), 50))
            
            #######################################################################
            ## Now create a panel of PNG files for maxent projections and MESS maps
            ## All the projections and extents need to match
            empty_ras <- init(pred.current, function(x) NA) 
            projection(novel_current_poly);projection(occ);projection(empty_ras);projection(poly)
            projection(pred.current);projection(pred.future)
            identical(extent(pred.current), extent(pred.future))
            
            ## Assign the scenario name (to use in the plot below)
            scen_name = eval(parse(text = sprintf('gcms.%s$GCM[gcms.%s$id == x]', time_slice, time_slice)))      
            
            #########################################################################
            ## Use the 'levelplot' function to make a multi-panel 
			## output: occurrence points, current raster and future raster
            if(create_mess == "TRUE") {
              message('Create MESS panel maps for ', species, ' under ', x, ' scenario')
              
              
              ############################################################
              ## Create level plot of current conditions including MESS                        
              png(sprintf('%s/%s/full/%s_%s.png', maxent_path, species, species, "mess_panel"),      
                  11, 4, units = 'in', res = 300)
              
              print(levelplot(stack(empty_ras,
                                    pred.current, quick = TRUE), margin = FALSE,
                              
                              ## Create a colour scheme using colbrewer: 100 is to make it continuos
                              ## Also, make it a one-directional colour scheme
                              scales      = list(draw = FALSE), 
                              at = seq(0, 1, length = 100),
                              col.regions = colorRampPalette(rev(brewer.pal(11, 'Spectral'))),
                              
                              ## Give each plot a name: the third panel is the GCM
                              names.attr = c('Australian records', 'Current'),
                              colorkey   = list(height = 0.5, width = 3), xlab = '', ylab = '',
                              main       = list(gsub('_', ' ', species), font = 4, cex = 2)) +
                      
                      ## Plot the Aus shapefile with the occurrence points for reference
                      ## Can the current layer be plotted on it's own?
                      ## Add the novel maps as vectors.              
                      latticeExtra::layer(sp.polygons(aus_poly), data = list(aus_poly = aus_poly)) +
                      latticeExtra::layer(sp.points(occ, pch = 19, cex = 0.15, 
                                                    col = c('red', 'transparent', 'transparent')
													[panel.number()]), data = list(occ = occ)) +
                      latticeExtra::layer(sp.polygons(h[[panel.number()]]), data = list(h = novel_hatch)))
              dev.off()
                           
              ############################################################
              ## Create level plot of scenario x, including MESS                        
              png(sprintf('%s/%s/full/%s_%s.png', maxent_path, species, species, x),      
                  11, 4, units = 'in', res = 300)
              
              ## Create a panel of the Australian occurrences, the current layer and the future layer
              print(levelplot(stack(empty_ras,
                                    pred.current, 
                                    pred.future, quick = TRUE), margin = FALSE,
                              
                              ## Create a colour scheme using colbrewer: 100 is to make it continuos
                              ## Also, make it a one-directional colour scheme
                              scales      = list(draw = FALSE), 
                              at = seq(0, 1, length = 100),
                              col.regions = colorRampPalette(rev(brewer.pal(11, 'Spectral'))),
                              
                              ## Give each plot a name: the third panel is the GCM
                              names.attr = c('Australian records', 'Current', 
							  sprintf('%s, 20%s, RCP8.5', scen_name, time_slice)),
                              colorkey   = list(height = 0.5, width = 3), xlab = '', ylab = '',
                              main       = list(gsub('_', ' ', species), font = 4, cex = 2)) +
                      
                      ## Plot the Aus shapefile with the occurrence points for reference
                      ## Can the current layer be plotted on it's own?
                      ## Add the novel maps as vectors.              
                      latticeExtra::layer(sp.polygons(aus_poly), data = list(aus_poly = aus_poly)) +
                      latticeExtra::layer(sp.points(occ, pch = 19, cex = 0.15, 
                                                    col = c('red', 'transparent', 'transparent')[
													panel.number()]), data = list(occ = occ)) +
                      latticeExtra::layer(sp.lines(h[[panel.number()]]), data = list(h = novel_hatch)))
              dev.off()
              
            } else {
              
              ############################################################
              ## OR Create level plot without MESS maps                        
              message('Create panel maps for ', species, ' under ', x, ' scenario')
              png(sprintf('%s/%s/full/%s_%s.png', maxent_path, species, species, x),      
                  11, 4, units = 'in', res = 300)
              
              ## Create levelplot without MESS maps
              print(levelplot(stack(empty_ras,
                                    pred.current, 
                                    pred.future, quick = TRUE), margin = FALSE,
                              
                              ## Create a colour scheme using colbrewer: 100 is to make it continuous
                              ## Also, make it a one-directional colour scheme
                              scales      = list(draw = FALSE), 
                              at = seq(0, 1, length = 100),
                              col.regions = colorRampPalette(rev(brewer.pal(11, 'Spectral'))),
                              
                              ## Give each plot a name: the third panel is the GCM
                              names.attr = c('Australian records', 'Current', 
							  sprintf('%s, 20%s, RCP8.5', scen_name, time_slice)),
                              colorkey   = list(height = 0.5, width = 3), xlab = '', ylab = '',
                              main       = list(gsub('_', ' ', species), font = 4, cex = 2)) +
                      
                      ## Plot the Aus shapefile with the occurrence points for reference
                      ## Can the points be made more legible for both poorly and well recorded species?
                      ## layer(sp.polygons(aus_albers), data = list(aus_albers = aus_albers))
                      latticeExtra::layer(sp.polygons(aus_poly), data = list(aus_poly = aus_poly)) +
                      latticeExtra::layer(sp.points(occ, pch = 19, cex = 0.15, 
                                                    col = c('red', 'transparent', 'transparent')
													[panel.number()]), data = list(occ = occ)))
              dev.off()                     
              
              message('Dont run MESS maps for ', species) 
              
            }
            
          }
          
        } else {
          
          message(species, ' ', x, ' skipped - prediction already run') 
          
        }
        
      } else {
        
        message(species, ' ', x, ' skipped - SDM not yet run')l
        
      }
      
    }
    
    if (nclust==1) {
      
      lapply(species_list, maxent_predict_fun) 
      
    } else {
      
      cl <- makeCluster(nclust)
      clusterExport(cl, c(
        'shp_path',    'aus_shp',       'world_shp',   'ALB.CONICAL',  'CRS.WGS.84',   
        'scen_list',   'species_list',  'maxent_path', 'climate_path', 'grid_names',  
        'time_slice',  'current_grids', 'create_mess', 'hatch', 'x',       
        'polygonizer', 'nclust', 'diverge0'),  envir = environment())
      
      # shp_path, aus_shp, world_shp, scen_list, 
      # species_list, maxent_path, climate_path, 
      # grid_names, time_slice, current_grids, create_mess, nclust
      
      clusterEvalQ(cl, {
        
        library(rmaxent)
        library(sp)
        library(raster)
        library(rasterVis)
        library(latticeExtra)
        library(magrittr)
        
      })
      
      message('Running project_maxent_grids_mess for ', length(species_list),
              ' species on ', nclust, ' cores for GCM ', x)
      
      parLapply(cl, species_list, maxent_predict_fun)  
    }
    
    
  })
  
} 

```

\

#########################################################################################################
## **Summarising change in climatic suitability** 
The maps generated by the function illustrate how climatic suitability varies across the landscape. 
In these maps, a grid cell is given a probability value between 0 (highly unsuitable) and 1 (highly suitable). 
Using a species-specific threshold – the 10th percentile training presence logistic threshold – based on the 
weighting of different model errors (‘commission’ errors, where a grid cell is classified as suitable when 
it is not, versus ‘omission’ errors, where a grid cell is classified as unsuitable when it is suitable) 
the maps were converted into binary representations of regions that are less or more suitable (0 or 1). 
Henceforth, we refer to these regions as ‘no to low suitability’ and ‘suitable’ regions, respectively. 
This terminology more clearly articulates the subjective nature of threshold selection.

\newpage 
![](output/figures/CV_figs/A_floribunda_continuous.png)

**Figure 2.** Example of a continuous climatic suitability map for one plant species under 
current conditions. Species occurrence points are plotted in red on the left panel. The cells in the right 
panel are coded from 0 : no to low suitability, to 1 : highly suitable. The shaded areas on the right panel
indicate where the maxent model is extrapolating beyond the training data (i.e. the result of a MESS map).

\

To combine the maps for each climate scenario, we then created a function to overlay and sum maps for all six 
scenarios, such that the value of a grid cell in the combined map could range from 0 (no to low suitability in 
all climate scenarios) to 6 (suitable in all climate scenarios). This function loops over three lists : a list 
of directories containing the maps, a list of species, and a list of maxent thresholds for all species analysed
(i.e. the climatic suitability maps below which species are not considered to occur in a grid cell).

\

```{r eval = FALSE, echo = TRUE}

#########################################################################################################
## A function which counts the number cells gained or lost for each species inside an SUA
tryCatch(mapply(SUA_cell_count,                                  ## Function aggregating GCM predictions
                unit_path     = "./data/base/CONTEXTUAL/SUA/",   ## Data path for the spatial unit
                unit_shp      = "SUA_2016_AUST.rds",             ## Spatial unit - E.G. urban areas
                unit_vec      = "SUA_2016_VEC.rds",              ## Vector of rasterized unit cells
                world_shp     = "LAND_world.rds",                ## Polygon for AUS maps
                aus_shp       = "aus_states.rds",                ## Polygon for World maps
                
                DIR_list      = SDM.RESULTS.DIR,                 ## List of raster directories
                species_list  = map_spp,                         ## List of species
                maxent_path   = bs_path,                         ## Directory of maxent results
                thresholds    = percent.10.log,                  ## List of maxent thresholds
                time_slice    = 30,                              ##Time period, eg 2030
                write_rasters = TRUE),
         
         #If the species fails, write a fail message to file.
         error = function(cond) {
           
           #This will write the error message inside the text file, 
           file.create(file.path(bs_path, "sua_count_failed_2030.txt"))
           cat(cond$message, file=file.path(bs_path, "sua_count_failed_2030.txt"))
           warning(cond$message)
           
         })

```

\

The combined maps were then re-coded to indicate whether grid cells were classified as suitable 
in the majority of climate scenarios (i.e. at least four of the six scenarios). These grid cells 
are most likely to be climatically suitable for the modelled species in the future. We then 
calculated percent changes to the size of suitable climate in terms of 
(i) overall change in size, 
(ii) loss of baseline suitable areas and (iii) gain of newly suitable areas. 

\

The function also intersects species' maps with Significant Urban Areas (SUAs) from the 2016 ABS Australian Census. 
It calculates the area predicted to be climatically suitable within the 82 temperature SUAs under current climate, 
and the extent to which this area may change under the future scenarios. Preliminary analyses demonstrated 
that environmental space tends to be poorly characterised by Maxent background samples in arid/tropical 
SUAs, further justifying the exclusion of these SUAs from results.


```{r eval = FALSE, echo = TRUE}

########################################################################
## Loop over directories, species and one threshold for each species
SUA_cell_count = function(unit_path, unit_file, unit_vec, 
                          DIR_list, species_list, 
                          maxent_path, thresholds, percentiles, 
                          time_slice, write_rasters) {

  ######################################################################
  ## Read in shapefiles 
  areal_unit = readRDS(paste0(unit_path, unit_file)) %>%
    spTransform(ALB.CONICAL)
  areal_unit = areal_unit[order(areal_unit$SUA_NAME16),] 
  
  areal_unit_vec  = readRDS(paste0(unit_path, unit_vec)) 
  
  ## Loop over each directory
  lapply(DIR_list, function(DIR) { 
    
    ## And each species 
    lapply(species_list, function(species) {
      
      ####################################################################
      ## Create a list of the rasters in each directory, then take the mean. T
      message('Running summary of SDM predictions within SUAs for ', species, 
              ' using ', names(areal_unit)[1], " shapefile")
      message('Calcualting mean of 20', time_slice, ' GCMs for ', species)
      
      ## Check if the mean GCM raster exists
      f_mean = sprintf('%s/%s/full/%s_20%s_suitability_mean.tif', 
                       maxent_path, species, species, time_slice)
      
      ## The mean of the GCMs doesn't exist, create it
      if(!file.exists(f_mean)) { 
        
        raster.list       = list.files(as.character(DIR), 
                                       pattern = sprintf('bi%s.tif$', 
                                                         time_slice), full.names = TRUE)  
        suit              = stack(raster.list)
        suit.list         = unstack(suit)
        combo_suit_mean   = mean(suit)          

      } else {
        
        ## Create another level without the mean calculation
        raster.list = list.files(as.character(DIR), 
                                 pattern = sprintf('bi%s.tif$', time_slice), full.names = TRUE)  
        suit        = stack(raster.list)
        suit.list   = unstack(suit)
        
      }
      
      ######################################################################
      ## Then, create rasters that meet habitat suitability criteria thresholds
      for (thresh in thresholds) {
        
        ## Check if the SUA summary table exists
        SUA_file =   sprintf('%s/%s/full/%s_20%s_%s%s.csv', maxent_path,
                             species, species, time_slice, "SUA_cell_count_", thresh)
        
        ## The mean of the GCMs doesn't exist, create it
        if(file.exists(SUA_file)) { 
          
          message(species, ' SUA_table already exists, skip')
          next
          
        }
        
        for (percent in percentiles) {
          
          ## Print the species being analysed
          message('doing ', species, ' | Logistic > ', thresh, ' for 20', time_slice)
          
          ## Read in the current suitability raster
          f_current <- raster(sprintf('%s/%s/full/%s_current.tif', 
                                      maxent_path, species, species))
          
          ## First, create a simple function to threshold each of the rasters in raster.list
          thresh_greater  = function (x) {x > thresh}
          percent_greater = function (x) {x > percent}
          
          ## Then apply this to just the current suitability raster. 
          ## Maximum training sensitivity plus specificity Logistic threshold
          ## 10th percentile training presence training omission
          current_suit_thresh  = thresh_greater(f_current)
          current_suit_percent = percent_greater(f_current) 
          
  
          ################################################################################
          ## First, calculate the cells which are greater that the: 
          ## Maximum training sensitivity plus specificity Logistic threshold
          message('Running thresholds for ', species, ' | 20', 
                  time_slice, ' combined suitability > ', thresh)
          
          suit_ras1_thresh   = thresh_greater(suit.list[[1]])   
          suit_ras2_thresh   = thresh_greater(suit.list[[2]])
          suit_ras3_thresh   = thresh_greater(suit.list[[3]])
          suit_ras4_thresh   = thresh_greater(suit.list[[4]])   
          suit_ras5_thresh   = thresh_greater(suit.list[[5]])
          suit_ras6_thresh   = thresh_greater(suit.list[[6]])
          
          ## Then calculate the cells which are greater than the 
          ## 10th percentile training presence training omission
          suit_ras1_percent  = percent_greater(suit.list[[1]])
          suit_ras2_percent  = percent_greater(suit.list[[2]])
          suit_ras3_percent  = percent_greater(suit.list[[3]])
          suit_ras4_percent  = percent_greater(suit.list[[4]])
          suit_ras5_percent  = percent_greater(suit.list[[5]])
          suit_ras6_percent  = percent_greater(suit.list[[6]])
          
          #################################################################################
          ## Then sum them up: All the threshholds
          combo_suit_thresh   =  Reduce("+", list(suit_ras1_thresh, suit_ras2_thresh, suit_ras3_thresh,
                                                  suit_ras4_thresh, suit_ras5_thresh, suit_ras6_thresh))
          
          ## All the percentiles
          combo_suit_percent  =  Reduce("+", list(suit_ras1_percent, suit_ras2_percent, suit_ras3_percent,
                                                  suit_ras4_percent, suit_ras5_percent, suit_ras6_percent))
          
          #################################################################################
          ## For each species, create a binary raster with cells > 4 GCMs above the maxent 
          ## threshold = 1, and cells with < 4 GCMs = 0. 
          message('Calculating change for ', species, ' | 20', time_slice, ' combined suitability > ', thresh)
          
          ## Functions for thresholding rasters
          band_4           <- function(x) {ifelse(x >=  4, 1, 0) }
          combo_suit_4GCM  <- calc(combo_suit_thresh, fun = band_4)
          
          ##################################################################################
          ## Now create a raster of the gain, loss and stable
          ## Create a raster stack of the current and future rasters
          message ("Counting cells lost/gained/stable/never suitable per SUA")
          
          ## Create a table of cell counts using a raster stack of current and future data
          d <- as.data.frame(stack(current_suit_thresh, combo_suit_4GCM)[]) %>% 
            setNames(c('current', 'future')) %>% 
            mutate(SUA_CODE16 = areal_unit_vec,
                   cell_number = seq_len(ncell(current_suit_thresh))) %>% 
            as.tbl
          dim(d);summary(d)
          
          ## Then classify the cells of the raster stack into lost, gained, stable and never
          d2 <- d %>% 
            na.omit %>% 
            
            mutate(lost   = current == 1 & future == 0,
                   gained = current == 0 & future == 1,
                   stable = current == 1 & future == 1,
                   never  = current == 0 & future == 0,
                   nodata = is.na(current) | is.na(future)) 
          d2$class <- apply(select(d2, lost:never), 1, which)
          dim(d2)
          
          ## Then group the cell counts by SUA
          d3 <- d2 %>% 
            group_by(SUA_CODE16) %>%
            
            summarize(CURRENT_SUITABLE = sum(current, na.rm = TRUE),
                      FUTURE_SUITABLE  = sum(future,  na.rm = TRUE),
                      LOST             = sum(lost,    na.rm = TRUE),
                      GAINED           = sum(gained,  na.rm = TRUE),
                      STABLE           = sum(stable,  na.rm = TRUE),
                      NEVER            = sum(never,   na.rm = TRUE),
                      NODAT            = sum(nodata,  na.rm = TRUE),
                      n_cells = n()) %>% 
            
            ## Then calculate change between current and future
            mutate(CHANGE    = FUTURE_SUITABLE - CURRENT_SUITABLE,
                   GAIN_LOSS = ifelse(CHANGE < 0, 'LOSS', ifelse(CHANGE > 0, 'GAIN', 'STABLE')),
                   GAIN_LOSS = ifelse(CURRENT_SUITABLE == 0 & FUTURE_SUITABLE == 0, 'NEVER', GAIN_LOSS))
          dim(d3)
          
          ## Add the species column
          d4 = d3 %>% 
            join(areal_unit@data, .) %>%
            add_column(., SPECIES = species,    .after = "AREASQKM16") %>%
            add_column(., PERIOD  = time_slice, .after = "SPECIES")    %>%
            add_column(., THRESH  = thresh,     .after = "PERIOD")
          View(d4)
          
          ##################################################################################
          ## Now calculate the number of cells lost/gained/stable across Australia
          message ("Counting cells lost/gained/stable/never suitable across Australia")
          d5 <- stack(current_suit_thresh, combo_suit_4GCM)[]
          r <- raster(current_suit_thresh)
          z <- as.data.frame(d4)
          
          ## Then classify the raster stack to make each value (i.e. outcome) unique
          r[d5[, 1]==1 & d5[, 2]==0] <- 1  ## 1 in current raster and 0 in future = LOSS
          r[d5[, 1]==0 & d5[, 2]==1] <- 2  ## 0 in current raster and 1 in future = GAIN
          r[d5[, 1]==1 & d5[, 2]==1] <- 3  ## 1 in current raster and 1 in future = STABLE
          r[d5[, 1]==0 & d5[, 2]==0] <- 4  ## 0 in current raster and 0 in future = NEVER_SUIT
          
          ## Now convert the raster to a factor and assign lables to the levels
          gain_loss <- as.factor(r)
          levels(gain_loss)[[1]] <- data.frame(ID = 1:4, 
                                               label = c('Lost', 'Gained', 'Stable', 'Never_Suitable'))
          z <- as.data.frame(d5)
          
          ## The gain/loss raster could be intersected with the SUAs
          gain_loss_table      = table(z[, 1], z[, 2])
          gain_loss_df         = as.data.frame(raster::freq(gain_loss))
          gain_loss_df$SPECIES = species
          gain_loss_df$PERIOD  = time_slice
          
          names(gain_loss_df)  = c("CHANGE", "COUNT", "SPECIES", "PERIOD")
          gain_loss_df         = gain_loss_df[, c("SPECIES", "PERIOD", "CHANGE", "COUNT")]
          
          ## Change values and remove the NA row
          gain_loss_df$CHANGE[gain_loss_df$CHANGE == 1] <- "LOST"
          gain_loss_df$CHANGE[gain_loss_df$CHANGE == 2] <- "GAINED"
          gain_loss_df$CHANGE[gain_loss_df$CHANGE == 3] <- "STABLE"
          gain_loss_df$CHANGE[gain_loss_df$CHANGE == 4] <- "NEVER_SUIT"
          gain_loss_df = head(gain_loss_df, 4)
          head(gain_loss_df)
          
          ##################################################################################
          ## Save the continental gain/loss table
          write.csv(gain_loss_df, sprintf('%s/%s/full/%s_20%s_%s%s.csv', maxent_path,
                                          species, species, time_slice, "gain_loss_table_", thresh), 
                    row.names = FALSE)
          
          ##################################################################################
          ## Save the SUA gain/loss table
          write.csv(d4, sprintf('%s/%s/full/%s_20%s_%s%s.csv', maxent_path,
                                species, species, time_slice, "SUA_cell_count_", thresh), 
                    row.names = FALSE)
          
          ##################################################################################
          ## Now write the rasters
          ## If the rasters don't exist, write them for each species/threshold
          if(write_rasters == "TRUE") {
            
            ## Write the combined future raster with > 4 GCMs above the maximum training value
            message('Writing ', species, ' | 20', time_slice, ' 4 GCMs > ', percent)
            writeRaster(combo_suit_4GCM, sprintf('%s/%s/full/%s_20%s%s%s.tif', maxent_path,
                                                 species, species, time_slice, 
                                                 "_4GCMs_above_", thresh), overwrite = TRUE)
            
            ## Write out the gain/loss raster
            writeRaster(gain_loss, sprintf('%s/%s/full/%s_20%s%s%s.tif', maxent_path,
                                           species, species, time_slice, "_gain_loss_", thresh), 
                        datatype = 'INT2U', overwrite = TRUE)

          } else {
            
            message(' skip raster writing') 
            
          }
          
        }
        
      }
      
    })
    
  })
  
}

```

\newpage 
![](output/figures/CV_figs/A_floribunda_future.png)

**Figure 3.** Example of a combined map of change in climatic suitability from current conditions to 2070. 
Species occurrence points are plotted in red on the left panel. The cells in the right and bottom panels 
are coded as either lost (orange cells - present now but not in 2070 according to 4 or more GCMs), 
gained (green cells - absent now, but present in 2070), stable (blue cells - present now and in 2070), 
or never suitable (white cells - never present). 

\


Finally, we fitted generalised additive models (GAMs) to assess the relationship between both the mean 
annual temperature, and the maximum temperature of the warmest month (1960–1990) within an SUA
– averaged across grid cells – and (a) the percent of species lost (i.e. percent of species with suitable 
climate within the SUA during the baseline, that lacked suitable climate in the future) and gained 
(i.e. percent of species with suitable climate within the SUA in the future, but not during the baseline) 
and (b) the percent of the SUA's area that changed over time from (i) unsuitable to suitable or (ii) 
suitable to unsuitable averaged over all species. We used the mgcv R package [version 1.8.4, Wood, 2011; 
R Core Team, 2018] to fit GAMs, using a restricted maximum likelihood approach (i.e. REML). Note that 
we also fitted GAMs using annual precipitation (see Figs. S2–S5 in supporting information)
but the relationships show no pattern.

\

#########################################################################################################
# **<span style="color:blue"> Results </span>**
#########################################################################################################

#########################################################################################################
### **Climatically suitable habitat for horticultural tree species** 

Models for all 176 species had AUC and TSS values sufficiently high to indicate acceptable predictive 
power [median AUC = 0.869 (±0.6)and median TSS=0.6 (±0.09), see Table S1 in supplementary material,
Swets, 1988]. Overall, the spatial extent of climatically suitable habitat is predicted to decline 
from an average of 16,152 km2 (±9082 km2) in the baseline period to 13,043 km2 (±8924 km2) by 2030, 
and 12,300 km2(±,016 km2) by 2070. Of the 176 species, 73% are predicted to experience declines in 
the extent of climatically suitable habitat across their respective SUAs: 18% are predicted to lose N50% 
of this habitat by 2030, while 34% are predicted to lose N50% by 2070. Fourteen species(8%) were 
projected to have losses exceeding 90% of baseline climatically suitable habitat [e.g. Callitris oblonga 
(Pygmy cypress pine) and Acacia fimbriata (Brisbane golden wattle)]. In contrast, 11 species are predicted 
to experience increases in the extent of climatically suitable habitat of 50%, e.g. Ficus platypoda 
(Rock fig) and Brachychiton rupestris (Queensland bottle tree). Generally, suitable habitat is predicted 
to shift poleward. As such, species are likely to experience an extension of their southern (colder) 
range margin (e.g. Pongamia pinnata and Melia azedarach in Fig. 4), and/or a contraction of their 
northern (warmer) margin (e.g. Melia azedarach and Syzygium smithii in Fig. 4). However, some species – 
particularly those found along coastal regions of southeast Australia – may experience contraction at 
both range margins(see Syzygium smithii, Fig. 2).


\newpage 
![](output/figures/CV_figs/FIG_4_PICS.png)

**Figure 4.** Examples of horticulturally-important tree species for which their 
climatic distributions are predicted to expand (Pongamia pinnata), shift (Melia azedarach) 
and shrink (Syzygium smithii) for 2030 (black areas) and 2070 (orange areas), relative 
to their baseline distributions (grey areas). Australia’s temperate SUAs are plotted 
in pink on the baseline map. Images are freely available in the public domain from 
Wikimedia Commons (CC BY-SA 3.0) and credited to Alpsdake (Melia azedarach), 
L. Shyamal [Pongamia pinnata (Millettia pinnata)] and Akos Kokai (Syzygium smithii).


\


#########################################################################################################
## **Climatically suitable habitat for tree species within urban areas** 

SUAs were predicted to contain suitable climate for between 10 and 139 of the 176 species for the baseline 
period,with an average of 74 species(±30). By 2070, this average is predicted to decline to 63 species 
(±30) per SUA, with ten SUAs (eight in eastern Queensland and two in south-west Western Australia) predicted 
to have suitable climate for 50% fewer species (Fig. 5). However, 21 of the 82 SUAs may contain suitable
climate for more species by 2070, than during the baseline period, including Orange in NSW (50% more species), 
Wangaratta in Victoria(25%), and all five of the Tasmanian SUAs in this study (6–24%). Note that these SUAs 
predominantly occur in cooler regions.

\newpage 
![](output/figures/CV_figs/FIG_3_8_panel.png)

\

**Figure 5.** Scatter plots of projected changes to the climatically suitable habitat of 176 commercial 
native Australian tree species within 82 of Australia's Significant Urban Areas (SUAs) (y axis)
vs. current mean annual temperature of the SUA (x axis, a-d), and maximum temperature of the warmest month 
(MAXT, e–h), for 2030 (lighter points) and 2070 (darker points). Panels a,b, e and f show the number 
of species, within each SUA, for which climatically suitable habitat is absent under baseline conditions, 
but present in the future (grey=2030, black=2070), expressed as a proportion of the number of species with 
suitable conditions in the baseline (i.e. species ‘gained’). Panels c, d, g and h show the proportion of 
species within each SUA with suitable habitat under baseline conditions, that do not have suitable habitat 
in the future (i.e. species ‘lost’). The left panels are for all 82 SUAs, while the right panels are for 
the SUAs with area > 200 km2 and with population > 80,000. DE = deviance explained from generalised additive 
models (GAMs) of species gain/loss (y axis) in each SUA vs. the SUA MAXT (x axis).

\

In general, the spatial extent of climatically suitable habitat across SUAs was predicted to decline for the 
176 species analysed. That is, averaged across their representative species, 12.3% (±5.8%) of each SUA's
currently suitable area will no longer be suitable by 2070, although predicted gains of 6.3% (±4.3%) occur 
elsewhere within the SUA. SUAswith warmer baseline mean annual temperatures are predicted to have fewer tree 
species that experience increases in the spatial extent of suitable habitat, compared to cooler SUAs (Fig. 4). 
Similarly, the percentage of tree species predicted to experience losses in suitable habitat is
greater in warmer SUAs (e.g. 80% in Rockhampton, Queensland) than in cooler SUAs (e.g. 13% in Burnie, Tasmania). 
These patterns of change were consistent regardless of the area and population of the SUAs (Fig. 4).

\newpage 
![](output/figures/CV_figs/FIG_4_8_panel.png)

**Figure 6.** Scatter plots of changes to the percent of species with climatically suitable habitat within 
82 of Australia's Significant Urban Areas (SUAs) (y axis) vs. current mean annual temperature of the SUA 
(x axis, a–d), and maximum temperature of the warmest month (MAXT, e–h), for 2030 (lighter points) and 
2070 (darker points). ‘Range gained’ refers to the proportion of species in the future time period projected 
to experience a net increase in the spatial extent of suitable habitat within that SUA vs. baseline, while 
‘Range loss’ refers to the proportion of species projected to experience a net decrease in spatial extent 
of suitable habitat within that SUA. The left panels are for all 82 SUAs, while the right panels are for 
the SUAs with area > 200 km2 and with human population > 80,000. Deviance = deviance explained by generalised 
additive models (GAMs) of species range gain/loss (y axis) in each SUA vs. the SUA MAT/MAXT.

\

SUAs with warmer baseline mean annual temperature are predicted to have fewer tree species experience 
increases in suitable habitat compared to cooler SUAs (Fig. 6). Similarly, the percent of tree species 
predicted to experience losses in suitable habitat increases with increasing mean annual temperature 
within SUAs. These patterns of change were consistent regardless of the area and population of the SUAs 
(Fig. 6). In addition, the deviance explained by GAMs in the long term (2070) was higher than the model 
deviance in the short term (2030).


\newpage 
![](output/figures/CV_figs/FIG_2_barplots.png)

**Figure 7.** Based on predictions from a climate suitability model, barplots illustrate the percentage of 
native tree species with suitable habitat in the baseline period (1960-1990), that are predicted to experience 
gains (green) or losses (red) in the extent of suitable habitat over 82 Significant Urban Areas (SUA, left 
panels), and within the 19 largest SUAs (right panels), for 2030 (a-b) and 2070 (c-d). SUAs are ranked by 
current mean annual temperature (MAT, e.g. Hobart is the coolest SUA, Mackay the the warmest)

\



#########################################################################################################
# **<span style="color:blue"> Implications </span>**
#########################################################################################################

\

Climate suitability models (CSMs) for 176 commonly-planted, native Australian tree species show that 
climate change will likely reduce climatically suitable habitat within the majority of the 82 temperate and
subtropical urban areas included in this study. Patterns in the loss of climatically suitable habitat for 
urban species are broadly similar for predictions for plant species in natural ecosystems. That is, suitable
habitat for urban trees is generally contracting, and shifting polewards, similar to trends in natural 
populations [e.g. Hickling et al.,2006; O'Donnell et al., 2012; Butt et al., 2013]. This overarching pattern
is driven by the projection of a poleward shift in climate space in the underlying climate models: hence, 
generally within temperate and subtropical regions, species' low-latitude (here, northernmost) range margins 
are predicted to contract, while their high-latitude (southernmost) margins may extend into new areas.

\

Predicted shifts in climatically suitable habitat mean that urban areas in cooler regions (for example, 
the city of Orange in central westernNewSouthWales, and the city of Launceston in northern Tasmania),
are likely to experience smaller reductions in the number of species with suitable habitat than urban areas 
in warmer regions (such as the cities of Mackay and Brisbane in Queensland) (Fig. 8). This predicted
broad pattern of decreasing habitat along a gradient of increasing temperature supports previous studies 
based on realised climate niches(Jenerette et al., 2016; Kendal et al., 2018), which also demonstrated
that temperature is a key filter on trees in urban environments. Hence our results, combined with those 
of other studies quantifying climate niches of species (Jenerette et al., 2016; Kendal et al., 2018; McBride
and Laćan, 2018) indicate that a substantial proportion of the most common urban trees face climate change 
risks where they are currently planted.


\newpage 
![](output/figures/CV_figs/FIG_1_SUA_PLOT_crop.png)

**Figure 8.** The largest Significant Urban Areas (SUA) in each Australian 
State and Territory (Ade = Adelaide, Bris = Brisbane, Can = Canberra, Hob = Hobart, 
Mel = Melbourne; Per = Perth, Syd = Sydney - The Northern Territory was not included 
in this study, Australia’s temperate SUAs are plotted in pink). For each largest SUA, 
we plot the predicted change in average % of cells lost (orange), gained (green) and 
stable (light blue) in each SUA across all 176 species according to our climate 
suitability models, from baseline to 2070.

\

As with all CSM studies, it is important to highlight several key caveats. Firstly, due to the availability 
of quality occurrence and tree inventory data in eastern Australia, the majority of the 176 tree species
we modelled are temperate (e.g. Syzygium smithii, see Appendix, Table S2). It is possible that the responses 
of trees planted within tropical and sub-tropical SUAs may drive overall patterns of species turnover
in the warm temperate SUAs included in our study (e.g. city of Rockhampton in Queensland). Secondly, we 
have only considered macro-climatic variables in our CSMs. Clearly, other factors – from microclimate,
extreme weather events and edaphic conditions, to phenotypic plasticity [e.g. Singer et al., 2016; 
Senner et al., 2018; (Benito Garzon et al., 2019)] – will also influence the suitability of urban areas 
for particular species. 

\

Thirdly, the ability to adjust otherwise limiting variables, such as rainfall through the use of 
irrigation (Moore, 2016; Vogt et al., 2017), may enable some species to survive in urban areas
that CSMs suggest are unsuitable (e.g. espaliered fruit trees). Locations characterised by contractions 
in the range of climatically suitable habitat predicted here may also be able to support urban species 
via additional watering or provision of shade, and our findings can assist in identifying regions 
which may require new maintenance regimes in the future. Revised maintenance requirements are just 
one response to climate change in urbanised areas, and below we discuss further implications
for urban planning.

\

#########################################################################################################
## **Conclusions** 
The number of current horticultural tree species with suitable climate within Australia's SUAs 
is predicted to progressively decline as climate change intensifies, with more pronounced 
reductions in urban areas which are currently warmest. Our results show that climatic
‘opportunities’ for species differ markedly across the Australian continent, indicating 
that a proactive approach is needed to identify new climate-ready species and plantings for climate
change. The climate suitability model outputs we present provide a useful baseline assessment 
of the impact of climate change on urban tree species, but should not be used in isolation 
for urban forestry and planning. We advocate for an approach that combines multiple lines 
of evidence to assess plant responses to climatic factors, particularly to shorter-term extreme 
events – including measurements from plant traits and physiological experiments. 
Combinatorial/synthetic approaches like this promote a more holistic understanding of the 
resilience of urban plants and trees to climate change.

\

#########################################################################################################
# **TBC...**
#########################################################################################################